{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "available-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4435421910844898747\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 8861712384\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14101939853227276561\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hourly-crest",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.4.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages\n",
      "Requires: absl-py, numpy, tensorboard, google-pasta, typing-extensions, six, h5py, astunparse, opt-einsum, grpcio, termcolor, wheel, gast, tensorflow-estimator, flatbuffers, keras-preprocessing, protobuf, wrapt\n",
      "Required-by: \n",
      "Name: Keras\n",
      "Version: 2.2.5\n",
      "Summary: Deep Learning for humans\n",
      "Home-page: https://github.com/keras-team/keras\n",
      "Author: Francois Chollet\n",
      "Author-email: francois.chollet@gmail.com\n",
      "License: MIT\n",
      "Location: /home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages\n",
      "Requires: keras-preprocessing, scipy, numpy, h5py, pyyaml, keras-applications, six\n",
      "Required-by: autolab-perception\n",
      "Name: numpy\n",
      "Version: 1.19.2\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\n",
      "Home-page: https://www.numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: None\n",
      "License: BSD\n",
      "Location: /home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages\n",
      "Requires: \n",
      "Required-by: trimesh, tifffile, tensorflow, tensorboard, scipy, scikit-video, scikit-learn, scikit-image, PyWavelets, pyrender, plyfile, pandas, opt-einsum, opencv-python, open3d, matplotlib, Keras, Keras-Preprocessing, Keras-Applications, imageio, h5py, gym, autolab-perception, autolab-core\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow\n",
    "!pip show keras\n",
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-leave",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/frederik/Documents/GitHub/sd-maskrcnn\n",
      "WARNING:tensorflow:From /home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:Failed to import geometry msgs in rigid_transformations.py.\n",
      "WARNING:root:Failed to import ros dependencies in rigid_transforms.py\n",
      "WARNING:root:autolab_core not installed as catkin package, RigidTransform ros methods will be unavailable\n",
      "Using TensorFlow backend.\n",
      "load/prepare train data\n",
      "load/prepare validate train\n",
      "setting config\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet35\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     4\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 4\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  384\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  3\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [384 384   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               20\n",
      "MEAN_PIXEL                     [128, 128, 128]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           RealCamera_30k_adam_lr0.001\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                5634.25\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "create model\n",
      "WARNING:tensorflow:From /home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "Loading weights  new\n",
      "start training\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: models/realcamera_30k_adam_lr0.00120210311T1546/mask_rcnn_realcamera_30k_adam_lr0.001_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(?, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(?, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(?, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(?, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/sub:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(?, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(?, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(?, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(?,), dtype=int32), values=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(?, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/ROI/GatherV2_4_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/Adam/gradients/ROI/GatherV2_4_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/ROI/GatherV2_4_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/ROI/GatherV2_5_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/Adam/gradients/ROI/GatherV2_5_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/ROI/GatherV2_5_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/ROI/GatherV2_6_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/Adam/gradients/ROI/GatherV2_6_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/ROI/GatherV2_6_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/Adam/gradients/ROI/GatherV2_7_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/Adam/gradients/ROI/GatherV2_7_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/Adam/gradients/ROI/GatherV2_7_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/frederik/Documents/GitHub/sd-maskrcnn/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
      "Epoch 1/20\n",
      "5635/5634 [==============================] - 1946s 345ms/step - loss: 1.5140 - rpn_class_loss: 0.1629 - rpn_bbox_loss: 0.6414 - mrcnn_class_loss: 0.0711 - mrcnn_bbox_loss: 0.3155 - mrcnn_mask_loss: 0.3230 - val_loss: 1.3954 - val_rpn_class_loss: 0.1038 - val_rpn_bbox_loss: 0.5325 - val_mrcnn_class_loss: 0.0661 - val_mrcnn_bbox_loss: 0.3216 - val_mrcnn_mask_loss: 0.3714\n",
      "Epoch 2/20\n",
      "5635/5634 [==============================] - 1717s 305ms/step - loss: 0.7651 - rpn_class_loss: 0.0530 - rpn_bbox_loss: 0.3238 - mrcnn_class_loss: 0.0469 - mrcnn_bbox_loss: 0.1171 - mrcnn_mask_loss: 0.2244 - val_loss: 1.2932 - val_rpn_class_loss: 0.0806 - val_rpn_bbox_loss: 0.5592 - val_mrcnn_class_loss: 0.0759 - val_mrcnn_bbox_loss: 0.2634 - val_mrcnn_mask_loss: 0.3140\n",
      "Epoch 3/20\n",
      "5635/5634 [==============================] - 1737s 308ms/step - loss: 0.7736 - rpn_class_loss: 0.0550 - rpn_bbox_loss: 0.3222 - mrcnn_class_loss: 0.0484 - mrcnn_bbox_loss: 0.1199 - mrcnn_mask_loss: 0.2280 - val_loss: 1.2363 - val_rpn_class_loss: 0.0693 - val_rpn_bbox_loss: 0.6119 - val_mrcnn_class_loss: 0.0776 - val_mrcnn_bbox_loss: 0.1985 - val_mrcnn_mask_loss: 0.2789\n",
      "Epoch 4/20\n",
      "5635/5634 [==============================] - 1752s 311ms/step - loss: 0.6878 - rpn_class_loss: 0.0462 - rpn_bbox_loss: 0.2963 - mrcnn_class_loss: 0.0411 - mrcnn_bbox_loss: 0.1016 - mrcnn_mask_loss: 0.2025 - val_loss: 2.4213 - val_rpn_class_loss: 0.1872 - val_rpn_bbox_loss: 1.7011 - val_mrcnn_class_loss: 0.0637 - val_mrcnn_bbox_loss: 0.1888 - val_mrcnn_mask_loss: 0.2804\n",
      "Epoch 5/20\n",
      "5635/5634 [==============================] - 1758s 312ms/step - loss: 0.6927 - rpn_class_loss: 0.0450 - rpn_bbox_loss: 0.3074 - mrcnn_class_loss: 0.0412 - mrcnn_bbox_loss: 0.0995 - mrcnn_mask_loss: 0.1995 - val_loss: 1.0008 - val_rpn_class_loss: 0.1282 - val_rpn_bbox_loss: 0.4295 - val_mrcnn_class_loss: 0.0414 - val_mrcnn_bbox_loss: 0.1836 - val_mrcnn_mask_loss: 0.2178\n",
      "Epoch 6/20\n",
      "5635/5634 [==============================] - 1728s 307ms/step - loss: 0.6449 - rpn_class_loss: 0.0423 - rpn_bbox_loss: 0.2787 - mrcnn_class_loss: 0.0386 - mrcnn_bbox_loss: 0.0943 - mrcnn_mask_loss: 0.1908 - val_loss: 1.1853 - val_rpn_class_loss: 0.2788 - val_rpn_bbox_loss: 0.4915 - val_mrcnn_class_loss: 0.0512 - val_mrcnn_bbox_loss: 0.1483 - val_mrcnn_mask_loss: 0.2152\n",
      "Epoch 7/20\n",
      "5635/5634 [==============================] - 1716s 305ms/step - loss: 0.6483 - rpn_class_loss: 0.0405 - rpn_bbox_loss: 0.2818 - mrcnn_class_loss: 0.0379 - mrcnn_bbox_loss: 0.0953 - mrcnn_mask_loss: 0.1925 - val_loss: 1.0013 - val_rpn_class_loss: 0.0667 - val_rpn_bbox_loss: 0.5040 - val_mrcnn_class_loss: 0.0698 - val_mrcnn_bbox_loss: 0.1544 - val_mrcnn_mask_loss: 0.2061\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5635/5634 [==============================] - 1570s 279ms/step - loss: 0.6203 - rpn_class_loss: 0.0384 - rpn_bbox_loss: 0.2737 - mrcnn_class_loss: 0.0357 - mrcnn_bbox_loss: 0.0906 - mrcnn_mask_loss: 0.1815 - val_loss: 2.4111 - val_rpn_class_loss: 0.5359 - val_rpn_bbox_loss: 1.4178 - val_mrcnn_class_loss: 0.0776 - val_mrcnn_bbox_loss: 0.1512 - val_mrcnn_mask_loss: 0.2284\n",
      "Epoch 9/20\n",
      "5635/5634 [==============================] - 1579s 280ms/step - loss: 0.5983 - rpn_class_loss: 0.0388 - rpn_bbox_loss: 0.2600 - mrcnn_class_loss: 0.0356 - mrcnn_bbox_loss: 0.0863 - mrcnn_mask_loss: 0.1773 - val_loss: 2.1021 - val_rpn_class_loss: 0.2112 - val_rpn_bbox_loss: 1.4014 - val_mrcnn_class_loss: 0.0466 - val_mrcnn_bbox_loss: 0.1763 - val_mrcnn_mask_loss: 0.2663\n",
      "Epoch 10/20\n",
      "4083/5634 [====================>.........] - ETA: 7:17 - loss: 0.6286 - rpn_class_loss: 0.0449 - rpn_bbox_loss: 0.2755 - mrcnn_class_loss: 0.0363 - mrcnn_bbox_loss: 0.0902 - mrcnn_mask_loss: 0.1814"
     ]
    }
   ],
   "source": [
    "# training\n",
    "%cd ..\n",
    "!python3.7 tools/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-philippines",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # benchmarking\n",
    "%cd ..\n",
    "# downgrade numpy for benchmarking -> pickle issue \n",
    "!pip install numpy==1.16.2\n",
    "!pip show numpy\n",
    "!python3.7 tools/benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-pension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd-maskrcnn",
   "language": "python",
   "name": "sd-maskrcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
